{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n",
      "1.14.2\n",
      "1.0.1\n",
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os \n",
    "import glob\n",
    "import argparse\n",
    "import scipy as sy\n",
    "import sklearn as sk\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(sy.__version__)\n",
    "print(sk.__version__)\n",
    "\n",
    "\n",
    "modelName = \"model/model-photos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para preparar las imágenes\n",
    "def load_train(train_path, image_size, classes):\n",
    "    images = []\n",
    "    labels = []\n",
    "    img_names = []\n",
    "    cls = []\n",
    "\n",
    "    print('Going to read training images')\n",
    "    for fields in classes:   \n",
    "        index = classes.index(fields)\n",
    "        print('Now going to read {} files (Index: {})'.format(fields, index))\n",
    "        path = os.path.join(train_path, fields, '*g')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            #image = cv2.imread(fl)\n",
    "            #image = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
    "            #image = image.astype(np.float32)\n",
    "            image = Image.open(fl)\n",
    "            image = image.resize((image_size,image_size))\n",
    "            image = np.asarray( image, dtype=\"uint8\" )\n",
    "            image = image.astype('float32')\n",
    "            image = np.multiply(image, 1.0/255.0) \n",
    "            images.append(image)\n",
    "            label = np.zeros(len(classes))\n",
    "            label[index] = 1.0\n",
    "            labels.append(label)\n",
    "            flbase = os.path.basename(fl)\n",
    "            img_names.append(flbase)\n",
    "            cls.append(fields)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    img_names = np.array(img_names)\n",
    "    cls = np.array(cls)\n",
    "\n",
    "    return images, labels, img_names, cls\n",
    "\n",
    "def create_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def create_biases(size):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[size]))\n",
    "\n",
    "\n",
    "def create_convolutional_layer(input,\n",
    "               num_input_channels, \n",
    "               conv_filter_size,        \n",
    "               num_filters):  \n",
    "    \n",
    "    ## We shall define the weights that will be trained using create_weights function.\n",
    "    weights = create_weights(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\n",
    "    ## We create biases using the create_biases function. These are also trained.\n",
    "    biases = create_biases(num_filters)\n",
    "\n",
    "    ## Creating the convolutional layer\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                     filter=weights,\n",
    "                     strides=[1, 1, 1, 1],\n",
    "                     padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "\n",
    "    ## We shall be using max-pooling.  \n",
    "    layer = tf.nn.max_pool(value=layer,\n",
    "                            ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1],\n",
    "                            padding='SAME')\n",
    "    ## Output of pooling is fed to Relu which is the activation function for us.\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "    \n",
    "\n",
    "def create_flatten_layer(layer):\n",
    "    #We know that the shape of the layer will be [batch_size img_size img_size num_channels] \n",
    "    # But let's get it from the previous layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    ## Number of features will be img_height * img_width* num_channels. But we shall calculate it in place of hard-coding it.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "\n",
    "    ## Now, we Flatten the layer so we shall have to reshape to num_features\n",
    "    layer = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def create_fc_layer(input,          \n",
    "             num_inputs,    \n",
    "             num_outputs,\n",
    "             use_relu=True):\n",
    "    \n",
    "    #Let's define trainable weights and biases.\n",
    "    weights = create_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = create_biases(num_outputs)\n",
    "\n",
    "    # Fully connected layer takes input x and produces wx+b.Since, these are matrices, we use matmul function in Tensorflow\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "\n",
    "  def __init__(self, images, labels, img_names, cls):\n",
    "    self._num_examples = images.shape[0]\n",
    "\n",
    "    self._images = images\n",
    "    self._labels = labels\n",
    "    self._img_names = img_names\n",
    "    self._cls = cls\n",
    "    self._epochs_done = 0\n",
    "    self._index_in_epoch = 0\n",
    "\n",
    "  @property\n",
    "  def images(self):\n",
    "    return self._images\n",
    "\n",
    "  @property\n",
    "  def labels(self):\n",
    "    return self._labels\n",
    "\n",
    "  @property\n",
    "  def img_names(self):\n",
    "    return self._img_names\n",
    "\n",
    "  @property\n",
    "  def cls(self):\n",
    "    return self._cls\n",
    "\n",
    "  @property\n",
    "  def num_examples(self):\n",
    "    return self._num_examples\n",
    "\n",
    "  @property\n",
    "  def epochs_done(self):\n",
    "    return self._epochs_done\n",
    "\n",
    "  def next_batch(self, batch_size):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    start = self._index_in_epoch\n",
    "    self._index_in_epoch += batch_size\n",
    "\n",
    "    if self._index_in_epoch > self._num_examples:\n",
    "      # After each epoch we update this\n",
    "      self._epochs_done += 1\n",
    "      start = 0\n",
    "      self._index_in_epoch = batch_size\n",
    "      assert batch_size <= self._num_examples\n",
    "    end = self._index_in_epoch\n",
    "\n",
    "    return self._images[start:end], self._labels[start:end], self._img_names[start:end], self._cls[start:end]\n",
    "\n",
    "\n",
    "def read_train_sets(train_path, image_size, classes, validation_size):\n",
    "  class DataSets(object):\n",
    "    pass\n",
    "  data_sets = DataSets()\n",
    "\n",
    "  images, labels, img_names, cls = load_train(train_path, image_size, classes)\n",
    "  images, labels, img_names, cls = shuffle(images, labels, img_names, cls)  \n",
    "\n",
    "  if isinstance(validation_size, float):\n",
    "    validation_size = int(validation_size * images.shape[0])\n",
    "\n",
    "  validation_images = images[:validation_size]\n",
    "  validation_labels = labels[:validation_size]\n",
    "  validation_img_names = img_names[:validation_size]\n",
    "  validation_cls = cls[:validation_size]\n",
    "\n",
    "  train_images = images[validation_size:]\n",
    "  train_labels = labels[validation_size:]\n",
    "  train_img_names = img_names[validation_size:]\n",
    "  train_cls = cls[validation_size:]\n",
    "\n",
    "  data_sets.train = DataSet(train_images, train_labels, train_img_names, train_cls)\n",
    "  data_sets.valid = DataSet(validation_images, validation_labels, validation_img_names, validation_cls)\n",
    "\n",
    "  return data_sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to read training images\n",
      "Now going to read personas files (Index: 0)\n",
      "Now going to read animales files (Index: 1)\n",
      "Now going to read urbano files (Index: 2)\n",
      "Now going to read paisaje files (Index: 3)\n",
      "Now going to read transporte files (Index: 4)\n",
      "Complete reading input data. Will Now print a snippet of it\n",
      "Number of files in Training-set:\t\t200\n",
      "Number of files in Validation-set:\t50\n"
     ]
    }
   ],
   "source": [
    "#Adding Seed so that random initialization is consistent\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "batch_size = 32\n",
    "\n",
    "#Prepare input data\n",
    "classes = ['personas','animales','urbano','paisaje','transporte']\n",
    "num_classes = len(classes)\n",
    "\n",
    "# 20% of the data will automatically be used for validation\n",
    "validation_size = 0.2\n",
    "img_size = 128\n",
    "num_channels = 3\n",
    "train_path='/Users/alejandro/GitHub/image_clasification/dataset/'\n",
    "# We shall load all the training and validation images and labels into memory using openCV and use that during training\n",
    "data = read_train_sets(train_path, img_size, classes, validation_size=validation_size)\n",
    "\n",
    "\n",
    "print(\"Complete reading input data. Will Now print a snippet of it\")\n",
    "print(\"Number of files in Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"Number of files in Validation-set:\\t{}\".format(len(data.valid.labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-16164a4b09c7>:7: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From <ipython-input-7-16164a4b09c7>:52: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "Training Epoch 1 --- Training Accuracy:  12.5%, Validation Accuracy:  31.2%,  Validation Loss: 1.563\n",
      "Training Epoch 2 --- Training Accuracy:  37.5%, Validation Accuracy:  18.8%,  Validation Loss: 1.643\n",
      "Training Epoch 3 --- Training Accuracy:  18.8%, Validation Accuracy:  12.5%,  Validation Loss: 1.634\n",
      "Training Epoch 4 --- Training Accuracy:  43.8%, Validation Accuracy:  28.1%,  Validation Loss: 1.597\n",
      "Training Epoch 5 --- Training Accuracy:  53.1%, Validation Accuracy:  46.9%,  Validation Loss: 1.574\n",
      "Training Epoch 6 --- Training Accuracy:  53.1%, Validation Accuracy:  43.8%,  Validation Loss: 1.565\n",
      "Training Epoch 7 --- Training Accuracy:  56.2%, Validation Accuracy:  43.8%,  Validation Loss: 1.556\n",
      "Training Epoch 8 --- Training Accuracy:  53.1%, Validation Accuracy:  50.0%,  Validation Loss: 1.535\n",
      "Training Epoch 9 --- Training Accuracy:  56.2%, Validation Accuracy:  50.0%,  Validation Loss: 1.504\n",
      "Training Epoch 10 --- Training Accuracy:  56.2%, Validation Accuracy:  50.0%,  Validation Loss: 1.473\n",
      "Training Epoch 11 --- Training Accuracy:  59.4%, Validation Accuracy:  50.0%,  Validation Loss: 1.435\n",
      "Training Epoch 12 --- Training Accuracy:  59.4%, Validation Accuracy:  50.0%,  Validation Loss: 1.395\n",
      "Training Epoch 13 --- Training Accuracy:  59.4%, Validation Accuracy:  50.0%,  Validation Loss: 1.350\n",
      "Training Epoch 14 --- Training Accuracy:  62.5%, Validation Accuracy:  50.0%,  Validation Loss: 1.310\n",
      "Training Epoch 15 --- Training Accuracy:  62.5%, Validation Accuracy:  53.1%,  Validation Loss: 1.273\n",
      "Training Epoch 16 --- Training Accuracy:  65.6%, Validation Accuracy:  50.0%,  Validation Loss: 1.242\n",
      "Training Epoch 17 --- Training Accuracy:  62.5%, Validation Accuracy:  50.0%,  Validation Loss: 1.224\n",
      "Training Epoch 18 --- Training Accuracy:  65.6%, Validation Accuracy:  46.9%,  Validation Loss: 1.205\n",
      "Training Epoch 19 --- Training Accuracy:  65.6%, Validation Accuracy:  46.9%,  Validation Loss: 1.194\n",
      "Training Epoch 20 --- Training Accuracy:  65.6%, Validation Accuracy:  46.9%,  Validation Loss: 1.184\n",
      "Training Epoch 21 --- Training Accuracy:  65.6%, Validation Accuracy:  46.9%,  Validation Loss: 1.176\n",
      "Training Epoch 22 --- Training Accuracy:  68.8%, Validation Accuracy:  46.9%,  Validation Loss: 1.169\n",
      "Training Epoch 23 --- Training Accuracy:  68.8%, Validation Accuracy:  46.9%,  Validation Loss: 1.163\n",
      "Training Epoch 24 --- Training Accuracy:  71.9%, Validation Accuracy:  46.9%,  Validation Loss: 1.160\n",
      "Training Epoch 25 --- Training Accuracy:  75.0%, Validation Accuracy:  46.9%,  Validation Loss: 1.149\n",
      "Training Epoch 26 --- Training Accuracy:  78.1%, Validation Accuracy:  46.9%,  Validation Loss: 1.143\n",
      "Training Epoch 27 --- Training Accuracy:  78.1%, Validation Accuracy:  46.9%,  Validation Loss: 1.137\n",
      "Training Epoch 28 --- Training Accuracy:  78.1%, Validation Accuracy:  46.9%,  Validation Loss: 1.128\n",
      "Training Epoch 29 --- Training Accuracy:  84.4%, Validation Accuracy:  46.9%,  Validation Loss: 1.120\n",
      "Training Epoch 30 --- Training Accuracy:  87.5%, Validation Accuracy:  46.9%,  Validation Loss: 1.111\n",
      "Training Epoch 31 --- Training Accuracy:  87.5%, Validation Accuracy:  43.8%,  Validation Loss: 1.099\n",
      "Training Epoch 32 --- Training Accuracy:  87.5%, Validation Accuracy:  43.8%,  Validation Loss: 1.091\n",
      "Training Epoch 33 --- Training Accuracy:  87.5%, Validation Accuracy:  43.8%,  Validation Loss: 1.081\n",
      "Training Epoch 34 --- Training Accuracy:  87.5%, Validation Accuracy:  43.8%,  Validation Loss: 1.072\n",
      "Training Epoch 35 --- Training Accuracy:  93.8%, Validation Accuracy:  43.8%,  Validation Loss: 1.062\n",
      "Training Epoch 36 --- Training Accuracy:  93.8%, Validation Accuracy:  43.8%,  Validation Loss: 1.055\n",
      "Training Epoch 37 --- Training Accuracy:  93.8%, Validation Accuracy:  46.9%,  Validation Loss: 1.048\n",
      "Training Epoch 38 --- Training Accuracy:  93.8%, Validation Accuracy:  50.0%,  Validation Loss: 1.041\n",
      "Training Epoch 39 --- Training Accuracy:  93.8%, Validation Accuracy:  53.1%,  Validation Loss: 1.036\n",
      "Training Epoch 40 --- Training Accuracy:  93.8%, Validation Accuracy:  53.1%,  Validation Loss: 1.030\n",
      "Training Epoch 41 --- Training Accuracy:  93.8%, Validation Accuracy:  50.0%,  Validation Loss: 1.024\n",
      "Training Epoch 42 --- Training Accuracy:  93.8%, Validation Accuracy:  53.1%,  Validation Loss: 1.024\n",
      "Training Epoch 43 --- Training Accuracy:  93.8%, Validation Accuracy:  53.1%,  Validation Loss: 1.017\n",
      "Training Epoch 44 --- Training Accuracy:  93.8%, Validation Accuracy:  53.1%,  Validation Loss: 1.018\n",
      "Training Epoch 45 --- Training Accuracy:  93.8%, Validation Accuracy:  53.1%,  Validation Loss: 1.020\n",
      "Training Epoch 46 --- Training Accuracy:  96.9%, Validation Accuracy:  53.1%,  Validation Loss: 1.015\n",
      "Training Epoch 47 --- Training Accuracy:  96.9%, Validation Accuracy:  53.1%,  Validation Loss: 1.013\n",
      "Training Epoch 48 --- Training Accuracy:  96.9%, Validation Accuracy:  56.2%,  Validation Loss: 1.010\n",
      "Training Epoch 49 --- Training Accuracy:  96.9%, Validation Accuracy:  56.2%,  Validation Loss: 1.017\n",
      "Training Epoch 50 --- Training Accuracy:  96.9%, Validation Accuracy:  56.2%,  Validation Loss: 1.019\n",
      "Training Epoch 51 --- Training Accuracy:  96.9%, Validation Accuracy:  59.4%,  Validation Loss: 1.018\n",
      "Training Epoch 52 --- Training Accuracy:  96.9%, Validation Accuracy:  59.4%,  Validation Loss: 1.021\n",
      "Training Epoch 53 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.027\n",
      "Training Epoch 54 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 1.027\n",
      "Training Epoch 55 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 1.032\n",
      "Training Epoch 56 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.037\n",
      "Training Epoch 57 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 1.037\n",
      "Training Epoch 58 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 1.045\n",
      "Training Epoch 59 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 1.048\n",
      "Training Epoch 60 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 1.047\n",
      "Training Epoch 61 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 1.056\n",
      "Training Epoch 62 --- Training Accuracy: 100.0%, Validation Accuracy:  53.1%,  Validation Loss: 1.052\n",
      "Training Epoch 63 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 1.068\n",
      "Training Epoch 64 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 1.069\n",
      "Training Epoch 65 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 1.078\n",
      "Training Epoch 66 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 1.079\n",
      "Training Epoch 67 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.091\n",
      "Training Epoch 68 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.091\n",
      "Training Epoch 69 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.104\n",
      "Training Epoch 70 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.106\n",
      "Training Epoch 71 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.114\n",
      "Training Epoch 72 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.120\n",
      "Training Epoch 73 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.127\n",
      "Training Epoch 74 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.132\n",
      "Training Epoch 75 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 76 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.147\n",
      "Training Epoch 77 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.155\n",
      "Training Epoch 78 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.163\n",
      "Training Epoch 79 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.169\n",
      "Training Epoch 80 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.176\n",
      "Training Epoch 81 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.184\n",
      "Training Epoch 82 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.188\n",
      "Training Epoch 83 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.197\n",
      "Training Epoch 84 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.203\n",
      "Training Epoch 85 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.213\n",
      "Training Epoch 86 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.216\n",
      "Training Epoch 87 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.226\n",
      "Training Epoch 88 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.231\n",
      "Training Epoch 89 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.238\n",
      "Training Epoch 90 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.245\n",
      "Training Epoch 91 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.250\n",
      "Training Epoch 92 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.262\n",
      "Training Epoch 93 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.264\n",
      "Training Epoch 94 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.271\n",
      "Training Epoch 95 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.280\n",
      "Training Epoch 96 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.285\n",
      "Training Epoch 97 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.294\n",
      "Training Epoch 98 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.299\n",
      "Training Epoch 99 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.306\n",
      "Training Epoch 100 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.310\n",
      "Training Epoch 101 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.320\n",
      "Training Epoch 102 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.325\n",
      "Training Epoch 103 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.330\n",
      "Training Epoch 104 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.338\n",
      "Training Epoch 105 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.343\n",
      "Training Epoch 106 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.349\n",
      "Training Epoch 107 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.356\n",
      "Training Epoch 108 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.361\n",
      "Training Epoch 109 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.367\n",
      "Training Epoch 110 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.374\n",
      "Training Epoch 111 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.379\n",
      "Training Epoch 112 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.383\n",
      "Training Epoch 113 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.392\n",
      "Training Epoch 114 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.397\n",
      "Training Epoch 115 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.399\n",
      "Training Epoch 116 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.408\n",
      "Training Epoch 117 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.412\n",
      "Training Epoch 118 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.418\n",
      "Training Epoch 119 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.423\n",
      "Training Epoch 120 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.430\n",
      "Training Epoch 121 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.435\n",
      "Training Epoch 122 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.438\n",
      "Training Epoch 123 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.446\n",
      "Training Epoch 124 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.449\n",
      "Training Epoch 125 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.454\n",
      "Training Epoch 126 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.459\n",
      "Training Epoch 127 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.467\n",
      "Training Epoch 128 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.471\n",
      "Training Epoch 129 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.474\n",
      "Training Epoch 130 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.480\n",
      "Training Epoch 131 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.486\n",
      "Training Epoch 132 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.489\n",
      "Training Epoch 133 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.494\n",
      "Training Epoch 134 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.499\n",
      "Training Epoch 135 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.503\n",
      "Training Epoch 136 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.509\n",
      "Training Epoch 137 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.514\n",
      "Training Epoch 138 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.518\n",
      "Training Epoch 139 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.523\n",
      "Training Epoch 140 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.527\n",
      "Training Epoch 141 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.530\n",
      "Training Epoch 142 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.535\n",
      "Training Epoch 143 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.540\n",
      "Training Epoch 144 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.544\n",
      "Training Epoch 145 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.548\n",
      "Training Epoch 146 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.554\n",
      "Training Epoch 147 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.557\n",
      "Training Epoch 148 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.562\n",
      "Training Epoch 149 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.566\n",
      "Training Epoch 150 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.570\n",
      "Training Epoch 151 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.575\n",
      "Training Epoch 152 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.579\n",
      "Training Epoch 153 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.583\n",
      "Training Epoch 154 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.586\n",
      "Training Epoch 155 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 156 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.595\n",
      "Training Epoch 157 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.598\n",
      "Training Epoch 158 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.604\n",
      "Training Epoch 159 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.607\n",
      "Training Epoch 160 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 1.610\n",
      "Training Epoch 161 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.614\n",
      "Training Epoch 162 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.618\n",
      "Training Epoch 163 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.623\n",
      "Training Epoch 164 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.626\n",
      "Training Epoch 165 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.631\n",
      "Training Epoch 166 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.633\n",
      "Training Epoch 167 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 1.637\n",
      "terminó\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size,img_size,num_channels], name='x')\n",
    "\n",
    "## labels\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "\n",
    "##Network graph params\n",
    "filter_size_conv1 = 3 \n",
    "num_filters_conv1 = 32\n",
    "\n",
    "filter_size_conv2 = 3\n",
    "num_filters_conv2 = 32\n",
    "\n",
    "filter_size_conv3 = 3\n",
    "num_filters_conv3 = 64\n",
    "    \n",
    "fc_layer_size = 128\n",
    "\n",
    "layer_conv1 = create_convolutional_layer(input=x,\n",
    "               num_input_channels=num_channels,\n",
    "               conv_filter_size=filter_size_conv1,\n",
    "               num_filters=num_filters_conv1)\n",
    "layer_conv2 = create_convolutional_layer(input=layer_conv1,\n",
    "               num_input_channels=num_filters_conv1,\n",
    "               conv_filter_size=filter_size_conv2,\n",
    "               num_filters=num_filters_conv2)\n",
    "\n",
    "layer_conv3= create_convolutional_layer(input=layer_conv2,\n",
    "               num_input_channels=num_filters_conv2,\n",
    "               conv_filter_size=filter_size_conv3,\n",
    "               num_filters=num_filters_conv3)\n",
    "          \n",
    "layer_flat = create_flatten_layer(layer_conv3)\n",
    "\n",
    "layer_fc1 = create_fc_layer(input=layer_flat,\n",
    "                     num_inputs=layer_flat.get_shape()[1:4].num_elements(),\n",
    "                     num_outputs=fc_layer_size,\n",
    "                     use_relu=True)\n",
    "\n",
    "layer_fc2 = create_fc_layer(input=layer_fc1,\n",
    "                     num_inputs=fc_layer_size,\n",
    "                     num_outputs=num_classes,\n",
    "                     use_relu=False) \n",
    "\n",
    "y_pred = tf.nn.softmax(layer_fc2,name='y_pred')\n",
    "\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "#session.run(tf.global_variables_initializer())\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#init = tf.initialize_all_variables()\n",
    "\n",
    "session.run(tf.global_variables_initializer()) \n",
    "\n",
    "#session.run(init) \n",
    "\n",
    "def show_progress(epoch, feed_dict_train, feed_dict_validate, val_loss):\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "    val_acc = session.run(accuracy, feed_dict=feed_dict_validate)\n",
    "    msg = \"Training Epoch {0} --- Training Accuracy: {1:>6.1%}, Validation Accuracy: {2:>6.1%},  Validation Loss: {3:.3f}\"\n",
    "    print(msg.format(epoch + 1, acc, val_acc, val_loss))\n",
    "\n",
    "total_iterations = 0\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "def train(num_iteration):\n",
    "    global total_iterations\n",
    "    \n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iteration):\n",
    "\n",
    "        x_batch, y_true_batch, _, cls_batch = data.train.next_batch(batch_size)\n",
    "        x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(batch_size)\n",
    "\n",
    "        \n",
    "        feed_dict_tr = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "        feed_dict_val = {x: x_valid_batch,\n",
    "                              y_true: y_valid_batch}\n",
    "\n",
    "        session.run(optimizer, feed_dict=feed_dict_tr)\n",
    "\n",
    "        if i % int(data.train.num_examples/batch_size) == 0: \n",
    "            val_loss = session.run(cost, feed_dict=feed_dict_val)\n",
    "            epoch = int(i / int(data.train.num_examples/batch_size))    \n",
    "            \n",
    "            show_progress(epoch, feed_dict_tr, feed_dict_val, val_loss)\n",
    "            saver.save(session, modelName) \n",
    "\n",
    "\n",
    "    total_iterations += num_iteration\n",
    "\n",
    "train(num_iteration=1000)\n",
    "session.close()\n",
    "print(\"terminó\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model-photos\n",
      "['personas', 'animales', 'urbano', 'paisaje', 'transporte']\n",
      "[[7.2074989e-05 5.2317610e-06 9.7338146e-01 7.2073448e-04 2.5820607e-02]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Predicción\n",
    "# First, pass the path of the image\n",
    "\n",
    "filename = '/Users/alejandro/Documents/Universidad/Integrador/TensorFlow/25.jpeg'\n",
    "\n",
    "image_size=128\n",
    "num_channels=3\n",
    "images = []\n",
    "# Reading the image using \n",
    "image = Image.open(filename)\n",
    "images = image.resize((image_size,image_size))\n",
    "images = np.asarray( images, dtype=\"uint8\" )\n",
    "images = images.astype('float32')\n",
    "images = np.multiply(images, 1.0/255.0) \n",
    "\n",
    "#The input to the network is of shape [None image_size image_size num_channels]. Hence we reshape.\n",
    "x_batch = images.reshape(1, image_size,image_size,num_channels)\n",
    "\n",
    "## Let us restore the saved model \n",
    "sess = tf.Session()\n",
    "# Step-1: Recreate the network graph. At this step only graph is created.\n",
    "meta = modelName + '.meta'\n",
    "\n",
    "saver = tf.train.import_meta_graph(meta)\n",
    "#saver = tf.train.import_meta_graph('dogs-cats-model.meta')\n",
    "# Step-2: Now let's load the weights saved using the restore method.\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./model/'))\n",
    "\n",
    "# Accessing the default graph which we have restored\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# Now, let's get hold of the op that we can be processed to get the output.\n",
    "# In the original network y_pred is the tensor that is the prediction of the network\n",
    "y_pred = graph.get_tensor_by_name(\"y_pred:0\")\n",
    "\n",
    "## Let's feed the images to the input placeholders\n",
    "x= graph.get_tensor_by_name(\"x:0\") \n",
    "y_true = graph.get_tensor_by_name(\"y_true:0\") \n",
    "y_test_images = np.zeros((1, 5)) \n",
    "\n",
    "\n",
    "### Creating the feed_dict that is required to be fed to calculate y_pred \n",
    "feed_dict_testing = {x: x_batch, y_true: y_test_images}\n",
    "result=sess.run(y_pred, feed_dict=feed_dict_testing)\n",
    "# result is of this format [probabiliy_of_rose probability_of_sunflower]\n",
    "sess.close()\n",
    "print(classes)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
