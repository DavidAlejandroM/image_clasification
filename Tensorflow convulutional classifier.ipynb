{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os \n",
    "import glob\n",
    "import argparse\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "modelName = \"model-photos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/alejandro/GitHub/image_clasification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para preparar las imágenes\n",
    "def load_train(train_path, image_size, classes):\n",
    "    images = []\n",
    "    labels = []\n",
    "    img_names = []\n",
    "    cls = []\n",
    "\n",
    "    print('Going to read training images')\n",
    "    for fields in classes:   \n",
    "        index = classes.index(fields)\n",
    "        print('Now going to read {} files (Index: {})'.format(fields, index))\n",
    "        path = os.path.join(train_path, fields, '*g')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            #image = cv2.imread(fl)\n",
    "            #image = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
    "            #image = image.astype(np.float32)\n",
    "            image = Image.open(fl)\n",
    "            image = image.resize((image_size,image_size))\n",
    "            image = np.asarray( image, dtype=\"uint8\" )\n",
    "            image = image.astype('float32')\n",
    "            image = np.multiply(image, 1.0/255.0) \n",
    "            images.append(image)\n",
    "            label = np.zeros(len(classes))\n",
    "            label[index] = 1.0\n",
    "            labels.append(label)\n",
    "            flbase = os.path.basename(fl)\n",
    "            img_names.append(flbase)\n",
    "            cls.append(fields)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    img_names = np.array(img_names)\n",
    "    cls = np.array(cls)\n",
    "\n",
    "    return images, labels, img_names, cls\n",
    "\n",
    "def create_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def create_biases(size):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[size]))\n",
    "\n",
    "\n",
    "def create_convolutional_layer(input,\n",
    "               num_input_channels, \n",
    "               conv_filter_size,        \n",
    "               num_filters):  \n",
    "    \n",
    "    ## We shall define the weights that will be trained using create_weights function.\n",
    "    weights = create_weights(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\n",
    "    ## We create biases using the create_biases function. These are also trained.\n",
    "    biases = create_biases(num_filters)\n",
    "\n",
    "    ## Creating the convolutional layer\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                     filter=weights,\n",
    "                     strides=[1, 1, 1, 1],\n",
    "                     padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "\n",
    "    ## We shall be using max-pooling.  \n",
    "    layer = tf.nn.max_pool(value=layer,\n",
    "                            ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1],\n",
    "                            padding='SAME')\n",
    "    ## Output of pooling is fed to Relu which is the activation function for us.\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "    \n",
    "\n",
    "def create_flatten_layer(layer):\n",
    "    #We know that the shape of the layer will be [batch_size img_size img_size num_channels] \n",
    "    # But let's get it from the previous layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    ## Number of features will be img_height * img_width* num_channels. But we shall calculate it in place of hard-coding it.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "\n",
    "    ## Now, we Flatten the layer so we shall have to reshape to num_features\n",
    "    layer = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def create_fc_layer(input,          \n",
    "             num_inputs,    \n",
    "             num_outputs,\n",
    "             use_relu=True):\n",
    "    \n",
    "    #Let's define trainable weights and biases.\n",
    "    weights = create_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = create_biases(num_outputs)\n",
    "\n",
    "    # Fully connected layer takes input x and produces wx+b.Since, these are matrices, we use matmul function in Tensorflow\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "\n",
    "  def __init__(self, images, labels, img_names, cls):\n",
    "    self._num_examples = images.shape[0]\n",
    "\n",
    "    self._images = images\n",
    "    self._labels = labels\n",
    "    self._img_names = img_names\n",
    "    self._cls = cls\n",
    "    self._epochs_done = 0\n",
    "    self._index_in_epoch = 0\n",
    "\n",
    "  @property\n",
    "  def images(self):\n",
    "    return self._images\n",
    "\n",
    "  @property\n",
    "  def labels(self):\n",
    "    return self._labels\n",
    "\n",
    "  @property\n",
    "  def img_names(self):\n",
    "    return self._img_names\n",
    "\n",
    "  @property\n",
    "  def cls(self):\n",
    "    return self._cls\n",
    "\n",
    "  @property\n",
    "  def num_examples(self):\n",
    "    return self._num_examples\n",
    "\n",
    "  @property\n",
    "  def epochs_done(self):\n",
    "    return self._epochs_done\n",
    "\n",
    "  def next_batch(self, batch_size):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    start = self._index_in_epoch\n",
    "    self._index_in_epoch += batch_size\n",
    "\n",
    "    if self._index_in_epoch > self._num_examples:\n",
    "      # After each epoch we update this\n",
    "      self._epochs_done += 1\n",
    "      start = 0\n",
    "      self._index_in_epoch = batch_size\n",
    "      assert batch_size <= self._num_examples\n",
    "    end = self._index_in_epoch\n",
    "\n",
    "    return self._images[start:end], self._labels[start:end], self._img_names[start:end], self._cls[start:end]\n",
    "\n",
    "\n",
    "def read_train_sets(train_path, image_size, classes, validation_size):\n",
    "  class DataSets(object):\n",
    "    pass\n",
    "  data_sets = DataSets()\n",
    "\n",
    "  images, labels, img_names, cls = load_train(train_path, image_size, classes)\n",
    "  images, labels, img_names, cls = shuffle(images, labels, img_names, cls)  \n",
    "\n",
    "  if isinstance(validation_size, float):\n",
    "    validation_size = int(validation_size * images.shape[0])\n",
    "\n",
    "  validation_images = images[:validation_size]\n",
    "  validation_labels = labels[:validation_size]\n",
    "  validation_img_names = img_names[:validation_size]\n",
    "  validation_cls = cls[:validation_size]\n",
    "\n",
    "  train_images = images[validation_size:]\n",
    "  train_labels = labels[validation_size:]\n",
    "  train_img_names = img_names[validation_size:]\n",
    "  train_cls = cls[validation_size:]\n",
    "\n",
    "  data_sets.train = DataSet(train_images, train_labels, train_img_names, train_cls)\n",
    "  data_sets.valid = DataSet(validation_images, validation_labels, validation_img_names, validation_cls)\n",
    "\n",
    "  return data_sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to read training images\n",
      "Now going to read personas files (Index: 0)\n",
      "Now going to read animales files (Index: 1)\n",
      "Complete reading input data. Will Now print a snippet of it\n",
      "Number of files in Training-set:\t\t80\n",
      "Number of files in Validation-set:\t20\n"
     ]
    }
   ],
   "source": [
    "#Adding Seed so that random initialization is consistent\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "batch_size = 16\n",
    "\n",
    "#Prepare input data\n",
    "classes = ['personas','animales']\n",
    "num_classes = len(classes)\n",
    "\n",
    "# 20% of the data will automatically be used for validation\n",
    "validation_size = 0.2\n",
    "img_size = 128\n",
    "num_channels = 3\n",
    "train_path='/Users/alejandro/GitHub/image_clasification/dataset/'\n",
    "# We shall load all the training and validation images and labels into memory using openCV and use that during training\n",
    "data = read_train_sets(train_path, img_size, classes, validation_size=validation_size)\n",
    "\n",
    "\n",
    "print(\"Complete reading input data. Will Now print a snippet of it\")\n",
    "print(\"Number of files in Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"Number of files in Validation-set:\\t{}\".format(len(data.valid.labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1 --- Training Accuracy:  56.2%, Validation Accuracy:  31.2%,  Validation Loss: 0.706\n",
      "Training Epoch 2 --- Training Accuracy:  56.2%, Validation Accuracy:  31.2%,  Validation Loss: 0.737\n",
      "Training Epoch 3 --- Training Accuracy:  75.0%, Validation Accuracy:  62.5%,  Validation Loss: 0.675\n",
      "Training Epoch 4 --- Training Accuracy:  62.5%, Validation Accuracy:  56.2%,  Validation Loss: 0.685\n",
      "terminó\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size,img_size,num_channels], name='x')\n",
    "\n",
    "## labels\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "\n",
    "##Network graph params\n",
    "filter_size_conv1 = 3 \n",
    "num_filters_conv1 = 32\n",
    "\n",
    "filter_size_conv2 = 3\n",
    "num_filters_conv2 = 32\n",
    "\n",
    "filter_size_conv3 = 3\n",
    "num_filters_conv3 = 64\n",
    "    \n",
    "fc_layer_size = 128\n",
    "\n",
    "layer_conv1 = create_convolutional_layer(input=x,\n",
    "               num_input_channels=num_channels,\n",
    "               conv_filter_size=filter_size_conv1,\n",
    "               num_filters=num_filters_conv1)\n",
    "layer_conv2 = create_convolutional_layer(input=layer_conv1,\n",
    "               num_input_channels=num_filters_conv1,\n",
    "               conv_filter_size=filter_size_conv2,\n",
    "               num_filters=num_filters_conv2)\n",
    "\n",
    "layer_conv3= create_convolutional_layer(input=layer_conv2,\n",
    "               num_input_channels=num_filters_conv2,\n",
    "               conv_filter_size=filter_size_conv3,\n",
    "               num_filters=num_filters_conv3)\n",
    "          \n",
    "layer_flat = create_flatten_layer(layer_conv3)\n",
    "\n",
    "layer_fc1 = create_fc_layer(input=layer_flat,\n",
    "                     num_inputs=layer_flat.get_shape()[1:4].num_elements(),\n",
    "                     num_outputs=fc_layer_size,\n",
    "                     use_relu=True)\n",
    "\n",
    "layer_fc2 = create_fc_layer(input=layer_fc1,\n",
    "                     num_inputs=fc_layer_size,\n",
    "                     num_outputs=num_classes,\n",
    "                     use_relu=False) \n",
    "\n",
    "y_pred = tf.nn.softmax(layer_fc2,name='y_pred')\n",
    "\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "#session.run(tf.global_variables_initializer())\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "#session.run(tf.global_variables_initializer()) \n",
    "\n",
    "session.run(init) \n",
    "\n",
    "def show_progress(epoch, feed_dict_train, feed_dict_validate, val_loss):\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "    val_acc = session.run(accuracy, feed_dict=feed_dict_validate)\n",
    "    msg = \"Training Epoch {0} --- Training Accuracy: {1:>6.1%}, Validation Accuracy: {2:>6.1%},  Validation Loss: {3:.3f}\"\n",
    "    print(msg.format(epoch + 1, acc, val_acc, val_loss))\n",
    "\n",
    "total_iterations = 0\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "def train(num_iteration):\n",
    "    global total_iterations\n",
    "    \n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iteration):\n",
    "\n",
    "        x_batch, y_true_batch, _, cls_batch = data.train.next_batch(batch_size)\n",
    "        x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(batch_size)\n",
    "\n",
    "        \n",
    "        feed_dict_tr = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "        feed_dict_val = {x: x_valid_batch,\n",
    "                              y_true: y_valid_batch}\n",
    "\n",
    "        session.run(optimizer, feed_dict=feed_dict_tr)\n",
    "\n",
    "        if i % int(data.train.num_examples/batch_size) == 0: \n",
    "            val_loss = session.run(cost, feed_dict=feed_dict_val)\n",
    "            epoch = int(i / int(data.train.num_examples/batch_size))    \n",
    "            \n",
    "            show_progress(epoch, feed_dict_tr, feed_dict_val, val_loss)\n",
    "            saver.save(session, modelName) \n",
    "\n",
    "\n",
    "    total_iterations += num_iteration\n",
    "\n",
    "train(num_iteration=20)\n",
    "session.close()\n",
    "print(\"terminó\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-photos.meta\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'import_meta_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e1ba96cdf57c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.meta'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m#saver = tf.train.import_meta_graph('dogs-cats-model.meta')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Step-2: Now let's load the weights saved using the restore method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'import_meta_graph'"
     ]
    }
   ],
   "source": [
    "\n",
    "#Predicción\n",
    "# First, pass the path of the image\n",
    "\n",
    "filename = '/Users/alejandro/Documents/Universidad/Integrador/TensorFlow/1.jpeg'\n",
    "\n",
    "image_size=128\n",
    "num_channels=3\n",
    "images = []\n",
    "# Reading the image using \n",
    "image = Image.open(filename)\n",
    "images = image.resize((image_size,image_size))\n",
    "images = np.asarray( images, dtype=\"uint8\" )\n",
    "images = images.astype('float32')\n",
    "images = np.multiply(images, 1.0/255.0) \n",
    "\n",
    "#The input to the network is of shape [None image_size image_size num_channels]. Hence we reshape.\n",
    "x_batch = images.reshape(1, image_size,image_size,num_channels)\n",
    "\n",
    "## Let us restore the saved model \n",
    "sess = tf.Session()\n",
    "# Step-1: Recreate the network graph. At this step only graph is created.\n",
    "meta = modelName + '.meta'\n",
    "print(meta)\n",
    "saver = tf.train.import_meta_graph(meta)\n",
    "#saver = tf.train.import_meta_graph('dogs-cats-model.meta')\n",
    "# Step-2: Now let's load the weights saved using the restore method.\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "\n",
    "# Accessing the default graph which we have restored\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# Now, let's get hold of the op that we can be processed to get the output.\n",
    "# In the original network y_pred is the tensor that is the prediction of the network\n",
    "y_pred = graph.get_tensor_by_name(\"y_pred:0\")\n",
    "\n",
    "## Let's feed the images to the input placeholders\n",
    "x= graph.get_tensor_by_name(\"x:0\") \n",
    "y_true = graph.get_tensor_by_name(\"y_true:0\") \n",
    "y_test_images = np.zeros((1, 2)) \n",
    "\n",
    "\n",
    "### Creating the feed_dict that is required to be fed to calculate y_pred \n",
    "feed_dict_testing = {x: x_batch, y_true: y_test_images}\n",
    "result=sess.run(y_pred, feed_dict=feed_dict_testing)\n",
    "# result is of this format [probabiliy_of_rose probability_of_sunflower]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
